<!doctype html>
<html lang="en">
<head>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Sudev Ambadi | Converting large csv's to nested data structure using apache spark</title>
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="Converting large csv&#39;s to nested data structure using apache spark">
  <meta property="og:type" content="website">
  <meta property="og:url" content="/posts/mongospark">
  <meta property="og:description" content="">
  <meta property="og:site_name" content="Sudev Ambadi">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:url" content="/posts/mongospark">
  <meta name="twitter:title" content="Converting large csv&#39;s to nested data structure using apache spark">
  <meta name="twitter:description" content="">

  
    <meta property="og:image" content="/assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">
    <meta name="twitter:image" content="/assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">
  

  <link href="/feed.xml" type="application/rss+xml" rel="alternate" title="Sudev Ambadi Last 10 blog posts" />

  

  
    <link rel="icon" type="image/x-icon" href="/assets/favicon-light-a98c41efc5ed9fcc06ac664c9e2f7a9b3c3b2e0a52357d221fe382f6f4abc8fc.ico">
    <link rel="apple-touch-icon" href="/assets/apple-touch-icon-light-87d1f2a3a19b1500e5c1626a0492025ca5f7f97d24540dc5900288e92112925a.png">
    <link rel="stylesheet" type="text/css" href="/assets/light-dd81b21ab090e25ca3de9c7f8a04c3ed3092374c826eb42b9fb7cac72c5f41e7.css">
  
</head>

<body>
  <main>
    <div class="grid grid-centered">
      <div class="grid-cell">
        <nav class="header-nav scrollappear">
  <a href="/" class="header-logo" title="Sudev Ambadi">Sudev Ambadi</a>
  <ul class="header-links">
    
      <li>
        <a href="/about" title="About me">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-about">
  <use href="/assets/about-ecf154b571ab8034ae00aeed91a3b7ad68db80b46d958753ad6216c919486e88.svg#icon-about" xlink:href="/assets/about-ecf154b571ab8034ae00aeed91a3b7ad68db80b46d958753ad6216c919486e88.svg#icon-about"></use>
</svg>

        </a>
      </li>
    
    
      <li>
        <a href="https://twitter.com/sudev" rel="noreferrer noopener" target="_blank" title="Twitter">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-twitter">
  <use href="/assets/twitter-8842c33965263ad1b03a978406826677a668f94125d5837e70ab83f24b3213a7.svg#icon-twitter" xlink:href="/assets/twitter-8842c33965263ad1b03a978406826677a668f94125d5837e70ab83f24b3213a7.svg#icon-twitter"></use>
</svg>

        </a>
      </li>
    
    
    
    
      <li>
        <a href="https://github.com/sudev" rel="noreferrer noopener" target="_blank" title="GitHub">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-github">
  <use href="/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github" xlink:href="/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github"></use>
</svg>

        </a>
      </li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
      <li>
        <a href="/feed.xml" rel="noreferrer noopener" target="_blank" title="RSS">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-rss">
  <use href="/assets/rss-541ec5cea9cefd10d2fcfec01888f3f231a8829940249835fa7b7b3a12ae0d0d.svg#icon-rss" xlink:href="/assets/rss-541ec5cea9cefd10d2fcfec01888f3f231a8829940249835fa7b7b3a12ae0d0d.svg#icon-rss"></use>
</svg>

        </a>
      </li>
    
  </ul>
</nav>

        <article class="article scrollappear">
          <header class="article-header">
            <h1>Converting large csv's to nested data structure using apache spark</h1>
            <p></p>
            <div class="article-list-footer">
              <span class="article-list-date">
                July 18, 2015
              </span>
              <span class="article-list-divider">-</span>
              <span class="article-list-minutes">
                
                
                  8 minute read
                
              </span>
              <span class="article-list-divider">-</span>
              <div class="article-list-tags">
                
                  <a href="/tag/Apache Spark">Apache Spark</a>
                
                  <a href="/tag/MongoDB">MongoDB</a>
                
                  <a href="/tag/large csv">large csv</a>
                
                  <a href="/tag/data cleaning">data cleaning</a>
                
                  <a href="/tag/reducebykey">reducebykey</a>
                
              </div>
            </div>
          </header>

          <div class="article-content">
            <h4 id="what-is-apache-spark-">What is Apache Spark ?</h4>
<p><a href="http://spark.apache.org/" title="Apache Spark homepage">Apache Spark</a> brings fast, in-memory data processing to Hadoop. Elegant and expressive development APIs in Scala, Java, and Python allow data workers to efficiently execute streaming, machine learning or SQL workloads for fast iterative access to datasets. <a href="http://spark.apache.org/docs/latest/quick-start.html" title="Spark quick start">Quick start guide</a></p>

<h4 id="problem-statement--task">Problem Statement / Task</h4>

<p>To read lot of really big csv’s (~GBs) from Hadoop HDFS, clean, convert them to nested data structure and update it to MongoDB using Apache Spark.
<br />
Recently I was assigned to create a Mongo collection with some select financial values by reading csv’s containing income statements, balance sheets … junk data.</p>

<figure class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">CompanyID</span><span class="p">,</span><span class="nx">USDAmount</span><span class="p">,</span><span class="nx">YearEnding</span><span class="p">,</span><span class="nx">Label</span><span class="p">,</span><span class="nx">BalSubCategoryName</span><span class="p">,</span><span class="nx">BalSubCategoryCode</span><span class="p">,</span><span class="nx">LabelOrderId</span><span class="p">,</span><span class="nx">SubCategoryOrder</span>
<span class="mi">1235</span><span class="p">,</span><span class="mf">14737.251</span><span class="p">,</span><span class="mi">31</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">2010</span><span class="p">,</span><span class="nx">Non</span><span class="o">-</span><span class="nx">Current</span> <span class="nx">Assets</span><span class="p">,</span><span class="nx">Intangible</span> <span class="nx">assets</span><span class="p">,</span><span class="nx">Non_Curr_Asset_Sub_03</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">152</span>
<span class="mi">1235</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">31</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">2009</span><span class="p">,</span><span class="nx">Non</span><span class="o">-</span><span class="nx">Current</span> <span class="nx">Assets</span><span class="p">,</span><span class="nx">Intangible</span> <span class="nx">assets</span><span class="p">,</span><span class="nx">Non_Curr_Asset_Sub_13</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">155</span>
<span class="mi">1235</span><span class="p">,</span><span class="mf">10733.189</span><span class="p">,</span><span class="mi">31</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">2011</span><span class="p">,</span><span class="nx">Non</span><span class="o">-</span><span class="nx">Current</span> <span class="nx">Assets</span><span class="p">,</span><span class="nx">Intangible</span> <span class="nx">assets</span><span class="p">,</span><span class="nx">Non_Curr_Asset_Sub_10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">125</span></code></pre></figure>

<p>Shown above is sample csv, I had to convert them into schema as shown below and update them to MongoDB. Consider a scenario where each csv is about ~ 1 GB and you have hundreds of them.</p>

<figure class="highlight"><pre><code class="language-js" data-lang="js"><span class="p">{</span>
    <span class="s2">"1235"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"2009"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"Non-CurrentAssets"</span><span class="p">:</span> <span class="mi">0</span>
        <span class="p">},</span>
        <span class="s2">"2010"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"Non-CurrentAssets"</span><span class="p">:</span> <span class="mi">14737</span>
        <span class="p">},</span>
        <span class="s2">"2011"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"Non-CurrentAssets"</span><span class="p">:</span> <span class="mf">10733.189</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<h5 id="approach">Approach</h5>

<ol>
  <li><em>Data Cleaning</em> - Read multiple types of csv’s and convert all of them into tuples of structure <code class="highlighter-rouge">(CompanyName, Map&lt;Year, Map&lt;TagName, Value&gt;&gt;&gt;)</code>.</li>
  <li><em>Union all created RDDs</em> - Join all the cleaned csv rdd into one.</li>
  <li><em>Reduce</em> - Reduce all tuples related to a company into single tuple considering companyName as the key.</li>
  <li><em>Update MongoDB</em> - Update MongoDB with reduced tuples.</li>
</ol>

<h4 id="data-cleaning">Data Cleaning</h4>

<p>The order of fields in the csv dump differs according to the type of csv, so I had to write a generic function wherein we can specify the position of required fields. So let’s call this function on both income-statement.csv and balance-sheet.csv and to create two cleaned rdd datasets  <code class="highlighter-rouge">balanceSheetRdd</code> and <code class="highlighter-rouge">incomeStatemntRdd</code> and later join them into one <code class="highlighter-rouge">masterRdd</code>.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// Function definition</span>
<span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;</span> <span class="nf">dataclean</span><span class="o">(</span>
			<span class="n">JavaSparkContext</span> <span class="n">sc</span><span class="o">,</span>                      <span class="c1">// Spark Context </span>
			<span class="n">String</span> <span class="n">filepath</span><span class="o">,</span>                         <span class="c1">// path to file in Hadoop</span>
			<span class="kd">final</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">filterTag</span><span class="o">,</span>             <span class="c1">// Required financial tags </span>
			<span class="kd">final</span> <span class="kt">int</span> <span class="n">pos_tag</span><span class="o">,</span>  <span class="kd">final</span> <span class="kt">int</span> <span class="n">pos_cname</span><span class="o">,</span> <span class="c1">// Position  </span>
			<span class="kd">final</span> <span class="kt">int</span> <span class="n">pos_date</span><span class="o">,</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">pos_value</span><span class="o">)</span></code></pre></figure>

<p>The <a href="https://github.com/databricks/spark-csv">spark-csv</a> plug-in can be used to read csv’s into a dataframe rdd, the plug-in is recommended over <code class="highlighter-rouge">map(line.split(","))</code> for its ability to handle quotes and malformed entries.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataFrame</span> <span class="n">df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="na">read</span><span class="o">()</span>
				<span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"com.databricks.spark.csv"</span><span class="o">)</span>
				<span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="n">filepath</span><span class="o">);</span>
<span class="c1">// spark-csv outputs dataframe to iterate line by line</span>
<span class="c1">// we will have to convert it to RDD of Rows</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">rowRdd</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="na">javaRDD</span><span class="o">();</span></code></pre></figure>

<p>Create two Java sets with required tags that we are planning to extract from the csv.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// Income Statement required tags </span>
<span class="kd">final</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">filterTagsIS</span> <span class="o">=</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">HashSet</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;();</span>
<span class="n">filterTagsIS</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"Revenue"</span><span class="o">);</span>
<span class="n">filterTagsIS</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"Cost of sales"</span><span class="o">);</span>
<span class="c1">// Balance Statement required tags</span>
<span class="kd">final</span> <span class="n">Set</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">filterTagsBS</span> <span class="o">=</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">HashSet</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;();</span>
<span class="n">filterTagsBS</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"Total Non Current Assets"</span><span class="o">);</span>
<span class="n">filterTagsBS</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"Total Assets"</span><span class="o">);</span></code></pre></figure>

<p>Filter out the unwanted tags using Sparks filter action.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">filteredRdd</span> <span class="o">=</span> <span class="n">rowRdd</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span> <span class="n">Function</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">,</span> <span class="n">Boolean</span><span class="o">&gt;()</span> <span class="o">{</span>  
<span class="nd">@Override</span>
<span class="kd">public</span> <span class="n">Boolean</span> <span class="nf">call</span><span class="o">(</span><span class="n">Row</span> <span class="n">r</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
	<span class="k">return</span> <span class="n">filterTag</span><span class="o">.</span><span class="na">contains</span><span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">pos_tag</span><span class="o">));</span>
<span class="o">}</span>
<span class="o">})</span></code></pre></figure>

<p>From the filtered rdd create a new PairRdd (tuple) of the form <code class="highlighter-rouge">(CompanyName, Map&lt;Year, Map&lt;TagName, Value&gt;&gt;&gt;)</code> using Spark mapToPair action.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">cleanedRdd</span> <span class="o">=</span> <span class="n">filteredRdd</span><span class="o">.</span><span class="na">mapToPair</span><span class="o">(</span> 
<span class="k">new</span> <span class="n">PairFunction</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;()</span> <span class="o">{</span>
	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;</span> <span class="nf">call</span><span class="o">(</span>
			<span class="n">Row</span> <span class="n">r</span><span class="o">)</span> <span class="o">{</span>
		<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">m1</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
		<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">m2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;();</span>
		<span class="n">String</span> <span class="n">label</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">pos_tag</span><span class="o">);</span>
		<span class="c1">// create a map of the form { Tag : value }</span>
		<span class="n">m1</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">r</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">pos_value</span><span class="o">));</span>
		<span class="n">String</span> <span class="n">year</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">pos_date</span><span class="o">).</span><span class="na">substring</span><span class="o">(</span>
				<span class="n">r</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">pos_date</span><span class="o">).</span><span class="na">length</span><span class="o">()</span> <span class="o">-</span> <span class="mi">4</span><span class="o">);</span>
		<span class="c1">// create a map of the form </span>
		<span class="c1">// { year :  { tag : value }   }</span>
		<span class="n">m2</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">year</span><span class="o">,</span> <span class="n">m1</span><span class="o">);</span>
		<span class="k">return</span> <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;(</span><span class="n">r</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">pos_cname</span><span class="o">),</span> <span class="n">m2</span><span class="o">);</span>
	<span class="o">}</span>
<span class="o">}</span>
<span class="o">);</span></code></pre></figure>

<p>Now we have cleaned the entire csv file contents into desirable format. Here I have arranged the filter and mapToPair actions into <a href="https://github.com/sudev/sparkMongo/blob/master/src/main/java/mongoDump/DataCleaning.java">data cleaning class</a>.</p>

<h4 id="union">Union</h4>

<p>Assuming we have created two rdd’s balanceSheetRdd and incomeStatemntRdd using above method. Make a master rdd using spark union transformation. From here on masterRdd will be instead of balanceSheetRdd and IncomeStatementRdd.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">masterRdd</span> <span class="o">=</span> <span class="n">balanceSheetRdd</span><span class="o">.</span><span class="na">union</span><span class="o">(</span><span class="n">incomeStatemntRdd</span><span class="o">)</span></code></pre></figure>

<h4 id="reduce">Reduce</h4>

<p>Reduce the master rdd with companyName as the key. Idea is to aggregate all financial details related to a company aggregated year wise. Calling <code class="highlighter-rouge">reduceByKey()</code> on masterRdd will produce iterable list using companyName as key but we need to do more here, we have to aggregate them according to year. We can do this by writing a custom class implementing Function2.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">reducedRdd</span> <span class="o">=</span> <span class="n">masterRdd</span><span class="o">.</span><span class="na">raduceByKey</span><span class="o">(</span><span class="k">new</span> <span class="n">reduceMaps</span><span class="o">())</span></code></pre></figure>

<p>Class reduceMaps, takes two tuples with same comapnyName and then reduces it by correctly grouping the tags by year.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="kd">class</span> <span class="nc">reduceMaps</span>
		<span class="kd">implements</span>
		<span class="n">Function2</span><span class="o">&lt;</span><span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;</span> <span class="o">{</span>
	<span class="kd">public</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="nf">call</span><span class="o">(</span>
			<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">map0</span><span class="o">,</span>
			<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">map1</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
		<span class="n">Set</span><span class="o">&lt;</span><span class="n">Entry</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;</span> <span class="n">emap0</span> <span class="o">=</span> <span class="n">map0</span><span class="o">.</span><span class="na">entrySet</span><span class="o">();</span>
		<span class="c1">// Iterate on map0 and update map1</span>
		<span class="k">for</span> <span class="o">(</span><span class="n">Entry</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">entry</span> <span class="o">:</span> <span class="n">emap0</span><span class="o">)</span> <span class="o">{</span>
			<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">val</span> <span class="o">=</span> <span class="n">map1</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">entry</span><span class="o">.</span><span class="na">getKey</span><span class="o">());</span>
			<span class="k">if</span> <span class="o">(</span><span class="n">val</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
				<span class="n">map1</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">entry</span><span class="o">.</span><span class="na">getKey</span><span class="o">(),</span> <span class="n">entry</span><span class="o">.</span><span class="na">getValue</span><span class="o">());</span>
			<span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
				<span class="c1">// If present, take union of inner map and replace</span>
				<span class="n">val</span><span class="o">.</span><span class="na">putAll</span><span class="o">(</span><span class="n">entry</span><span class="o">.</span><span class="na">getValue</span><span class="o">());</span>
				<span class="n">map1</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">entry</span><span class="o">.</span><span class="na">getKey</span><span class="o">(),</span> <span class="n">val</span><span class="o">);</span>
			<span class="o">}</span>
		<span class="o">}</span>
		<span class="k">return</span> <span class="n">map1</span><span class="o">;</span>
	<span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<h4 id="updating-mongodb">Updating MongoDB</h4>

<p>To update mongoDB using Spark use <a href="https://github.com/mongodb/mongo-hadoop/wiki/Spark-Usage" title="Hadoop Spark Mongo connector wiki">mongo-hadoop connector</a>. Before saving the rdd covert them into pairRdds of the type <code class="highlighter-rouge">JavaPairRDD&lt;Object, BSONObject&gt;</code>.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">mongoRdd</span> <span class="o">=</span> <span class="n">reducedRdd</span><span class="o">.</span><span class="na">mapToPair</span><span class="o">(</span> <span class="k">new</span> <span class="n">basicDBMongo</span><span class="o">())</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="kd">class</span> <span class="nc">basicDBMongo</span> <span class="kd">implements</span> <span class="n">PairFunction</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;,</span> <span class="n">Object</span><span class="o">,</span> <span class="n">BSONObject</span><span class="o">&gt;</span> <span class="o">{</span>
	<span class="kd">public</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Object</span><span class="o">,</span> <span class="n">BSONObject</span><span class="o">&gt;</span> <span class="nf">call</span><span class="o">(</span>
			<span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;&gt;</span> <span class="n">companyTuple</span><span class="o">)</span>
			<span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
		<span class="n">BasicBSONObject</span> <span class="n">report</span> <span class="o">=</span> <span class="k">new</span> <span class="n">BasicBSONObject</span><span class="o">();</span>
		<span class="c1">// Create a BSON of form { companyName : financeDetails } </span>
		<span class="n">report</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">companyTuple</span><span class="o">.</span><span class="na">_1</span><span class="o">(),</span> <span class="n">companyTuple</span><span class="o">.</span><span class="na">_2</span><span class="o">());</span>
		<span class="k">return</span> <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Object</span><span class="o">,</span> <span class="n">BSONObject</span><span class="o">&gt;(</span><span class="kc">null</span><span class="o">,</span> <span class="n">report</span><span class="o">);</span>
	<span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p>Updating mongoDB</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// Configurations for Mongo Hadoop Connector</span>
<span class="n">String</span> <span class="n">mongouri</span> <span class="o">=</span> <span class="s">"mongo:url/db/collectioName"</span>
<span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">conf</span><span class="o">.</span><span class="na">Configuration</span> <span class="n">midbconf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">conf</span><span class="o">.</span><span class="na">Configuration</span><span class="o">();</span>
<span class="n">midbconf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"mongo.output.format"</span><span class="o">,</span>
		<span class="s">"com.mongodb.hadoop.MongoOutputFormat"</span><span class="o">);</span>
<span class="n">midbconf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"mongo.output.uri"</span><span class="o">,</span> <span class="n">mongouri</span><span class="o">);</span>
<span class="c1">// Writing the rdd to Mongo</span>
<span class="n">mongordd</span><span class="o">.</span><span class="na">saveAsNewAPIHadoopFile</span><span class="o">(</span><span class="s">"file:///notapplicable"</span><span class="o">,</span> <span class="n">Object</span><span class="o">.</span><span class="na">class</span><span class="o">,</span>
				<span class="n">Object</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">MongoOutputFormat</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">midbconf</span><span class="o">);</span></code></pre></figure>

<p>Actually we did quiet a lot of things here. This is how the DAG looks for this job.</p>

<p><br /></p>

<figure class="one">
	<img src="/images/stages.PNG" />
	<figcaption>DAG for the job, helps in uderstanding and improving the whole process.</figcaption>
</figure>

<p><br /></p>

<p>Previously I had attempted to do this filtering and mapping jobs using dataframes, but the solution was not great. I like this program for the fact that I’m not collecting anything from rdds into driver anywhere and hence this should run distributed at each stage. I ran and tested this application on a Spark Standalone Cluster on HDP Stack with 4 nodes.</p>

<p><br /></p>

<figure class="one">
	<img src="/images/active.PNG" />
	<figcaption>The workload distributed evenly in cluster. Apache Spark :)</figcaption>
</figure>

<p><br /></p>

<p>Let me know your thoughts, please do comment. The entire <a href="https://github.com/sudev/sparkMongo">code is available in github</a>, this post intends to explain the same.</p>


          </div>
          <div class="article-share">
            
            
            <a href="https://twitter.com/home?status=Converting+large+csv's+to+nested+data+structure+using+apache+spark%20-%20/posts/mongospark%20by%20@sudev" title="Share on Twitter" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M492 109.5c-17.4 7.7-36 12.9-55.6 15.3 20-12 35.4-31 42.6-53.6 -18.7 11.1-39.4 19.2-61.5 23.5C399.8 75.8 374.6 64 346.8 64c-53.5 0-96.8 43.4-96.8 96.9 0 7.6 0.8 15 2.5 22.1 -80.5-4-151.9-42.6-199.6-101.3 -8.3 14.3-13.1 31-13.1 48.7 0 33.6 17.2 63.3 43.2 80.7C67 210.7 52 206.3 39 199c0 0.4 0 0.8 0 1.2 0 47 33.4 86.1 77.7 95 -8.1 2.2-16.7 3.4-25.5 3.4 -6.2 0-12.3-0.6-18.2-1.8 12.3 38.5 48.1 66.5 90.5 67.3 -33.1 26-74.9 41.5-120.3 41.5 -7.8 0-15.5-0.5-23.1-1.4C62.8 432 113.7 448 168.3 448 346.6 448 444 300.3 444 172.2c0-4.2-0.1-8.4-0.3-12.5C462.6 146 479 129 492 109.5z"/></svg>
            </a>
            <a href="https://www.facebook.com/sharer/sharer.php?u=/posts/mongospark" title="Share on Facebook" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M288 192v-38.1c0-17.2 3.8-25.9 30.5-25.9H352V64h-55.9c-68.5 0-91.1 31.4-91.1 85.3V192h-45v64h45v192h83V256h56.4l7.6-64H288z"/></svg>
            </a>
            <a href="https://plus.google.com/share?url=/posts/mongospark" title="Share on Google+" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 128 128"><path d="M40.7 55.9v16.1c0 0 15.6 0 22 0C59.2 82.5 53.8 88.2 40.7 88.2c-13.3 0-23.7-10.8-23.7-24.2s10.4-24.2 23.7-24.2c7.1 0 11.6 2.5 15.8 5.9 3.3-3.3 3.1-3.8 11.6-11.9 -7.2-6.6-16.8-10.6-27.4-10.6C18.2 23.3 0 41.5 0 64c0 22.5 18.2 40.7 40.7 40.7 33.6 0 41.8-29.3 39-48.8H40.7zM113.9 56.7V42.6h-10.1v14.1H89.4v10.1h14.5v14.5h10.1V66.8H128V56.7H113.9z"/></svg>
            </a>
          </div>

          
            <div id="disqus_thread" class="article-comments"></div>
            <script src="https://sudevgithub.disqus.com/embed.js" async defer></script>
            <noscript>Please enable JavaScript to view the comments.</noscript>
          
        </article>
        <footer class="footer scrollappear">
  <p>
    &copy; 2017 Sudev Ambadi. <br /> Unless noted otherwise, all content is available under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License. </a> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png" /></a><br />
    Powered by <a href="http://jekyllrb.com">Jekyll</a> and <a href="http://pages.github.com">Github pages</a> using <a href="http://chalk.nielsenramon.com/">Chalk</a> theme.
  </p>
</footer>

      </div>
    </div>
  </main>
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-39443594-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-39443594-1');
  </script>


<script type="text/javascript" src="/assets/vendor-2e5becc015a837c852edabccbc32f5a390d4afa7a2ca601db948ea5b9e50292a.js"></script>


  <script type="text/javascript" src="/assets/webfonts-e3010885de8c083c4b2935d463b1649e8796191a66a1b43bb87ef04bbcce420d.js"></script>



  <script type="text/javascript" src="/assets/scrollappear-e2da8ea567e418637e31266cc5302126eaa79f62a2273739086358b589a89ee6.js"></script>


<script type="text/javascript" src="/assets/application-cd43a7f9bd8a08997bb19229cd040e7129ede0a1adf77c693b5835c9f8c2a4b1.js"></script>

</body>
</html>
