<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		 
			
  
    <meta name="twitter:card" content="summary"/>
    
      <meta name="twitter:image" content="http://sudevambadi.me/images/avatar.png" />
    
  
  
  <meta name="twitter:title" content="Data science and unix command line"/>
  <meta name="twitter:description" content="Note : This article applies only to those who code. I have seen many strugling with MS Excel trying to figure out data in a large csv file, I don&rsquo;t blame them beacause most people I have met ignore standard unix command line tools just because they cared about commandline tools.

When the data is BIG(anything above .5GBs) and if we are trying to figure out say even the coloumn names of a csv file MS Excel will get stuck and we will see a MS Windows Not Responding."/>
  
    <meta name="twitter:site" content="@sudev"/>
  
  
  
  
    <meta name="twitter:creator" content="@Sudo"/>
  



		
		<meta name="author" content="Sudo">
		<meta name="description" content="My blog">
		<meta name="generator" content="Hugo 0.37.1" />
		<title>Data science and unix command line &middot; Sudev Ambadi</title>
		<link rel="shortcut icon" href="http://sudevambadi.me/images/favicon.ico">
		<link rel="stylesheet" href="http://sudevambadi.me/css/style.css">
		<link rel="stylesheet" href="http://sudevambadi.me/css/highlight.css">

		
		<link rel="stylesheet" href="http://sudevambadi.me/css/font-awesome.min.css">
		

		
		<link href="http://sudevambadi.me/index.xml" rel="alternate" type="application/rss+xml" title="Sudev Ambadi" />
		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='http://sudevambadi.me/'> <span class="arrow">←</span>Home</a>
	
	<a href='http://sudevambadi.me/posts'>Archive</a>
	<a href='http://sudevambadi.me/tags'>Tags</a>
	<a href='http://sudevambadi.me/about'>About</a>

	

	
	<a class="cta" href="http://sudevambadi.me/index.xml">Subscribe</a>
	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        Data science and unix command line
                    </h1>
                    <h2 class="headline">
                    Mar 20, 2015 00:00
                    · 1238 words
                    · 6 minute read
                      <span class="tags">
                      
                      
                          
                              <a href="http://sudevambadi.me/tags/unix-command-line">unix command line</a>
                          
                              <a href="http://sudevambadi.me/tags/text-manipulation">text manipulation</a>
                          
                              <a href="http://sudevambadi.me/tags/data-science">data science</a>
                          
                              <a href="http://sudevambadi.me/tags/data-science-large-files">data science large files</a>
                          
                              <a href="http://sudevambadi.me/tags/large-dataset">large dataset</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                  
                
                <section id="post-body">
                    <p>Note : <em>This article applies only to those who code</em>.
I have seen many strugling with MS Excel trying to figure out data in a large csv file, I don&rsquo;t blame them beacause most people I have met ignore standard unix command line tools just because they cared about commandline tools.</p>

<p><br />
<img src="/images/excel.jpg" alt="MS Excel for large dataset" /><br />
<br />
When the data is BIG(anything above .5GBs) and if we are trying to figure out say even the coloumn names of a csv file MS Excel will get stuck and we will see a MS Windows <code>Not Responding</code>. And if we are going to script using python/R/perl/* we will spend some time to script and more time for the script to complete.<br />
<br />
Assume that we have a csv &ldquo;car.csv&rdquo; as shown below:
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-csv" data-lang="csv">&#34;&#34;,&#34;mpg&#34;,&#34;cyl&#34;,&#34;disp&#34;,&#34;hp&#34;,&#34;drat&#34;,&#34;wt&#34;,&#34;qsec&#34;,&#34;vs&#34;,&#34;am&#34;,&#34;gear&#34;,&#34;carb&#34;
&#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
&#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
&#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
&#34;Hornet 4 Drive&#34;,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1
&#34;Hornet Sportabout&#34;,18.7,8,360,175,3.15,3.44,17.02,0,0,3,2
&#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
&#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
&#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4</code></pre></div></p>

<p>Let&rsquo;s assume that we have a BIG csv with many coloumns and we are interested in the sum of 12th coloumn (carb) of the file.</p>

<p><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-csv" data-lang="csv">cat car.csv | awk -F &#34;,&#34; &#39;{ sum += $12 } END { printf &#34;%.2f\n&#34;, sum}&#39;
# 29.00</code></pre></div>
Here we have used the standard command line tools <code>cat</code> and <code>awk</code> and we don&rsquo;t even load the entire data into memory.<br />
The above line says:</p>

<ol>
<li>Using <code>cat</code> stream the contents into <strong>stdout</strong></li>
<li>Pipe the stdout from <code>cat</code> to the next command <code>awk</code>.</li>
<li>With Awk

<ul>
<li><code>-F</code> parameter takes the deliminator that is used in big.csv.</li>
<li>once you specify the <code>-F</code> to deliminator all the fields will be available to you as { $1, $2 &hellip; }</li>
<li><code>sum += $12</code> will increment the variable sum with 12th coloumn of each line.</li>
<li>use <code>printf</code> to format result.</li>
</ul></li>
</ol>

<p>Other useful commands:
<br /> <br />
<em>Head and tail</em><br />
If we want to get a sample data from BIG csv. Again using head or tail command we are not loading the entire file into memory, we are just reading them line by line.</p>

<p><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-csv" data-lang="csv"># To get the first 3 lines of your csv 
head car.csv -n 3
# &#34;&#34;,&#34;mpg&#34;,&#34;cyl&#34;,&#34;disp&#34;,&#34;hp&#34;,&#34;drat&#34;,&#34;wt&#34;,&#34;qsec&#34;,&#34;vs&#34;,&#34;am&#34;,&#34;gear&#34;,&#34;carb&#34;
# &#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
# &#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4

# Similarly for the last 5 lines 
tail car.csv -n 3 
# &#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
# &#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
# &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1</code></pre></div>
We can even save the sample to a separate file to view them using a editor or to run some script over the sample file. Using the redirect operator <code>&gt;</code> in bash you can redirect the output to a file.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-csv" data-lang="csv"># first 100 lines into a new file first100.txt
head -n 100 big.csv &gt; first100.txt</code></pre></div></p>

<p><em>Word count</em><br />
<code>wc</code> command is used to get the number of line, words and bytes in your file
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-csv" data-lang="csv"># number of lines, words and bytes
wc car.csv
#  11  25 602 car.csv

# to only output number of lines 
wc -l car.csv
# 11</code></pre></div></p>

<p><em>Grep</em><br />
We wish to search for the line containing some text <code>Datsun</code> we can use grep to search and return those rows for you. Grep supports regular expression and hell lot of options.</p>

<p><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Search for text Datsun 
</span><span style="color:#75715e"></span>grep Datsun car.csv
<span style="color:#75715e"># &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
</span><span style="color:#75715e"># &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
</span><span style="color:#75715e"></span>
<span style="color:#75715e"># subset data with only lines containing Datsun
</span><span style="color:#75715e"></span>grep Datsun car.csv &gt; datsun.csv</code></pre></div>
<em>Cut</em><br />
Cut is used to cut a line into fields according to a given deliminator or number of characters or any pattern.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># To cut your csv and show only first and third coloumn
</span><span style="color:#75715e"></span>cut -d <span style="color:#e6db74">&#34;,&#34;</span> -f <span style="color:#ae81ff">1</span>,3 car.csv
<span style="color:#75715e"># &#34;&#34;,&#34;cyl&#34;
</span><span style="color:#75715e"># &#34;Mazda RX4&#34;,6
</span><span style="color:#75715e"># &#34;Mazda RX4 Wag&#34;,6
</span><span style="color:#75715e"># &#34;Datsun 710&#34;,4
</span><span style="color:#75715e"># &#34;Hornet 4 Drive&#34;,6
</span><span style="color:#75715e"># &#34;Hornet Sportabout&#34;,8
</span><span style="color:#75715e"># &#34;Mazda RX4&#34;,6
</span><span style="color:#75715e"># &#34;Mazda RX4 Wag&#34;,6
</span><span style="color:#75715e"># &#34;Mazda RX4&#34;,6
</span><span style="color:#75715e"># &#34;Mazda RX4 Wag&#34;,6
</span><span style="color:#75715e"># &#34;Datsun 710&#34;,4
</span><span style="color:#75715e"></span>
<span style="color:#75715e"># You can cut by specifying start/end/number of characters 
</span><span style="color:#75715e"># To print only first 3 characters 
</span><span style="color:#75715e"></span>cut -c-3 car.csv
<span style="color:#75715e"># &#34;&#34;,&#34;m
</span><span style="color:#75715e"># &#34;Mazd
</span><span style="color:#75715e"># &#34;Mazd
</span><span style="color:#75715e"># &#34;Dats
</span><span style="color:#75715e"># &#34;Horn
</span><span style="color:#75715e"># &#34;Horn
</span><span style="color:#75715e"># &#34;Mazd
</span><span style="color:#75715e"># &#34;Mazd
</span><span style="color:#75715e"># &#34;Mazd
</span><span style="color:#75715e"># &#34;Mazd
</span><span style="color:#75715e"></span># <span style="color:#e6db74">&#34;Dats</span></code></pre></div></p>

<p><em>Sed and Awk</em><br />
These two commands are more of a programing language than being just commands. We use sed and Awk to find and replace, count, add, basically to manipulate data.
Sed/Awk again combined with some regular expression will let we to do most manipulations on a text file.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Replace all occurence of &#34;Mazda&#34; to &#34;Maa&#34; in your data.
</span><span style="color:#75715e"></span>sed s/Mazda/Maa/g car.csv
<span style="color:#75715e"># &#34;&#34;,&#34;mpg&#34;,&#34;cyl&#34;,&#34;disp&#34;,&#34;hp&#34;,&#34;drat&#34;,&#34;wt&#34;,&#34;qsec&#34;,&#34;vs&#34;,&#34;am&#34;,&#34;gear&#34;,&#34;carb&#34;
</span><span style="color:#75715e"># &#34;Maa RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"># &#34;Maa RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
</span><span style="color:#75715e"># &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
</span><span style="color:#75715e"># &#34;Hornet 4 Drive&#34;,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1
</span><span style="color:#75715e"># &#34;Hornet Sportabout&#34;,18.7,8,360,175,3.15,3.44,17.02,0,0,3,2
</span><span style="color:#75715e"># &#34;Maa RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"># &#34;Maa RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
</span><span style="color:#75715e"># &#34;Maa RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"># &#34;Maa RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
</span><span style="color:#75715e"></span># <span style="color:#e6db74">&#34;Datsun 710&#34;</span>,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1</code></pre></div>
Sed can be used to clean your dataset, mostly we find our data with unwanted characters and which needs to be ignored. Say we wish to delete all the lines containing Mazda.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Delete all the lines containing Mazda 
</span><span style="color:#75715e"></span>sed /Mazda/d car.csv &gt; noMazda.csv</code></pre></div>
Read more about <a href="https://en.wikipedia.org/wiki/Sed">Sed</a> and <a href="https://en.wikipedia.org/wiki/Awk">Awk</a>.<br />
<br />
<em>Sort and uniq</em><br />
Using sort command will sort the csv treating each line as a single string, we can use sort to even sort based on a coloumn, numerical order or in reverse order. Uniq can be used to return only uniq rows or return the duplicated ones.
<br />
Say you want to sort a csv according to coloumn 12 (carb), -k (key) specifies the coloumn to sorted, -nr specifies sort to sort in reverse numeric order and -t specifies the coloumn deliminator.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># if you want to sort the csv according to carb(Coloumn 12)
</span><span style="color:#75715e"></span>sort -k <span style="color:#ae81ff">12</span> -nr -t <span style="color:#e6db74">&#34;,&#34;</span> car.csv
<span style="color:#75715e"># &#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
</span><span style="color:#75715e"># &#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
</span><span style="color:#75715e"># &#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
</span><span style="color:#75715e"># &#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"># &#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"># &#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"># &#34;Hornet Sportabout&#34;,18.7,8,360,175,3.15,3.44,17.02,0,0,3,2
</span><span style="color:#75715e"># &#34;Hornet 4 Drive&#34;,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1
</span><span style="color:#75715e"># &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
</span><span style="color:#75715e"># &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
</span><span style="color:#75715e"></span># <span style="color:#e6db74">&#34;&#34;</span>,<span style="color:#e6db74">&#34;mpg&#34;</span>,<span style="color:#e6db74">&#34;cyl&#34;</span>,<span style="color:#e6db74">&#34;disp&#34;</span>,<span style="color:#e6db74">&#34;hp&#34;</span>,<span style="color:#e6db74">&#34;drat&#34;</span>,<span style="color:#e6db74">&#34;wt&#34;</span>,<span style="color:#e6db74">&#34;qsec&#34;</span>,<span style="color:#e6db74">&#34;vs&#34;</span>,<span style="color:#e6db74">&#34;am&#34;</span>,<span style="color:#e6db74">&#34;gear&#34;</span>,<span style="color:#e6db74">&#34;carb&#34;</span></code></pre></div>
Use uniq command to output only the uniq rows, -c flag will also append the number occurences as the first coloumn for each row.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sort car.csv | uniq -c
<span style="color:#75715e"># 2 &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
</span><span style="color:#75715e"># 1 &#34;Hornet 4 Drive&#34;,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1
</span><span style="color:#75715e"># 1 &#34;Hornet Sportabout&#34;,18.7,8,360,175,3.15,3.44,17.02,0,0,3,2
</span><span style="color:#75715e"># 3 &#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"># 3 &#34;Mazda RX4 Wag&#34;,21,6,160,110,3.9,2.875,17.02,0,1,4,4
</span><span style="color:#75715e"></span># <span style="color:#ae81ff">1</span> <span style="color:#e6db74">&#34;&#34;</span>,<span style="color:#e6db74">&#34;mpg&#34;</span>,<span style="color:#e6db74">&#34;cyl&#34;</span>,<span style="color:#e6db74">&#34;disp&#34;</span>,<span style="color:#e6db74">&#34;hp&#34;</span>,<span style="color:#e6db74">&#34;drat&#34;</span>,<span style="color:#e6db74">&#34;wt&#34;</span>,<span style="color:#e6db74">&#34;qsec&#34;</span>,<span style="color:#e6db74">&#34;vs&#34;</span>,<span style="color:#e6db74">&#34;am&#34;</span>,<span style="color:#e6db74">&#34;gear&#34;</span>,<span style="color:#e6db74">&#34;carb&#34;</span></code></pre></div>
To see only the duplicate lines pass a -d flag.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sort car.csv | uniq -d
<span style="color:#75715e"># &#34;Datsun 710&#34;,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
</span><span style="color:#75715e"># &#34;Mazda RX4&#34;,21,6,160,110,3.9,2.62,16.46,0,1,4,4
</span><span style="color:#75715e"></span># <span style="color:#e6db74">&#34;Mazda RX4 Wag&#34;</span>,21,6,160,110,3.9,2.875,17.02,0,1,4,4</code></pre></div>
To get total number of uniq lines pipe <code>uniq</code> output to <code>wc</code>.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sort car.csv | uniq | wc -l
<span style="color:#ae81ff">6</span></code></pre></div>
<em>GNU split</em><br />
Sometimes you just want to split the file into n small parts and run your script over these n part files.
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e">#Split the csv into part files of 100 lines
</span><span style="color:#75715e"></span>split big.csv --lines <span style="color:#ae81ff">100</span></code></pre></div>
The file will be splitted into part  files as { xaa, xab &hellip; } in the same folder.<br />
<br />
<em>GNU Plot</em><br />
GNU plot is awesome tool for plotting. Read <a href="http://gnuplot.sourceforge.net/demo_cvs/">more</a>.<br />
<br />
I just want to say that working with unix command line tools is easier than using any other graphical tools, all you have to do is to try them for once. There are many custom tools to ease your workflow like jsontoCsv, GNU plot etc check them out. High level scripting languages can do a lot, I&rsquo;m big fan of python but then using unix commandline is so much easier and reliable IMHO. R is pretty good tool too, but when data gets bigger R sucks, use commandline to make data small and tidy for R.<br />
<em>And you dont have to remember any of these parameters that we passed to unix commands, always use man page!</em><br />
<br />
Links:</p>

<ul>
<li><a href="http://jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html">Using command line for datascience, huge collection!</a></li>
<li><a href="https://github.com/fosscell/bashworkshop">A beginners guide that I wrote with abijith for fosscell juniors</a></li>
<li><a href="http://thelycaeum.in/blog/2013/09/03/text_processing_in_unix/">Noufal Ibrahim&rsquo;s unix blog post</a></li>
<li><a href="http://www.gregreda.com/2013/07/15/unix-commands-for-data-science/">I copied many examples from here</a></li>
</ul>

<hr />

                </section>
            </article>

            
                <a class="twitter" href="https://twitter.com/intent/tweet?text=http%3a%2f%2fsudevambadi.me%2fpost%2f2015-03-20-datascienceunix%2f - Data%20science%20and%20unix%20command%20line by @sudev"><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

            

            
                <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'sudevgithub'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://www.github.com/sudev">
        <i class="fa fa-github"></i>
    </a>
    
    <a class="symbol" href="https://www.twitter.com/sudev">
        <i class="fa fa-twitter"></i>
    </a>
    


</div>

    
    <p class="small">
    
        &copy; 2017 Sudev Ambadi. <br /> Unless noted otherwise, all content is available under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License. <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/"><img alt="Creative Commons License" style="width:80px;height:15px" src="http://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png" /></a>
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        <script src="http://sudevambadi.me/js/jquery-3.3.1.min.js"></script>
<script src="http://sudevambadi.me/js/main.js"></script>
<script src="http://sudevambadi.me/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-39443594-1', 'auto');
ga('send', 'pageview');
</script>





    </body>
</html>
