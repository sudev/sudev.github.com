---
categories:
- notes
comments: true
date: 2018-03-31T00:00:00Z
tags:
- Optimiser
- Database
- Spark
- SQL
title: Notes on Spark Sql / Catalyst Optimisers
draft: true
---



Hey, today I will try to share some of my learnings around realtional database(especially the query optimisers) and how the modern SQL engines like Spark SQL is trying to leverage the ideas and implementations from ~50 years of relational databases research. 

I will be extensibly refering to a and quoting lot from lot of research papers in this post, essentially this is a summary many papers that I have been reading recently. 



Before we jump into understanding the Spark SQL it will be lot easier if we get some basics of query optimization in relational systems. I will try to explain the same using few examples. 

#### Why is SQL usually performant than a program that we write to do the same task in programming  languages like C/Python?

Let's take an example. You have to join two CSVs using a common column and then filter out few of them and do some aggregation. 

In case of SQL you will write something like this. 

``` sql 
SELECT col1,
       AGGREGATION_FUNCTION_1(col1) AS col1_aggregated_value col2,
       AGGREGATION_FUNCTION_2(col2) AS col2_aggregated_value
FROM
  (SELECT col1,
          common_col
   FROM large_table) large_table
INNER JOIN
  (SELECT col2,
          common_col
   FROM small_table) small_table 
ON (large_table.common_table = small_table.common_table)
WHERE (large_table.col3 != NULL)
  AND (small_table.col4 = 0)
```



Let's think of writing a python program to do the same. Before you start writing a program you will have lot of questions in you like the ones below. 

* What datastructure to use? 
* Should I sort the two CSVs? (cost joining two unsorted datastructures can be too high)
* How can I reduce the memory footprint of program? Which table(s) should I keep in the memory and  which should I sequentially read from the disk(only keeping the current row in memory)? 
* What will be the order of the operations that I have to do? Should we do the filters `large_table.col3 != NULL`
  and `small_table.col4 = 0` first, then join the tables and do the aggregations? or should I join the tables, filter the columns and then aggregate? 

You will have to think through a lot of details before you can write a program which is faster and efficient. In case of Relational database answers to the above questions are taken care by different components within the relational database like . 

 

[chaudhuri98]: http://www.diku.dk/hjemmesider/ansatte/henglein/papers/chaudhuri1998.pdf	"An Overview of Query Optimization in Relational Systems"
[ papers ]: http://www.benjaminnevarez.com/2013/03/query-optimization-research-papers/ " Papers related to query optimization "

